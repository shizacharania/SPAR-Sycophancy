{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzYtZXWQUMqEX3v7MmqJYC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "wxtaZ6XhCwYC",
        "outputId": "3f8e3e19-7bd3-4f63-eebb-62b9ec6ffea7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprerequisites for step one and two of implementing reading vector:\\n- need to have pairs of size 5 to 128\\n- determine the hidden state values with respect to the chosen LAT token position (which is [-2] for us) + probably pick a layer we want\\n- compute differences between hidden states within each pair, which is already done\\n- we normalize the difference -> should be [128, 4096], which 128 being the sample pairs and 4096 being the activation vector size\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "prerequisites for step one and two of implementing reading vector:\n",
        "- need to have pairs of size 5 to 128\n",
        "- determine the hidden state values with respect to the chosen LAT token position (which is [-2] for us) + probably pick a layer we want\n",
        "- compute differences between hidden states within each pair, which is already done\n",
        "- we normalize the difference -> should be [128, 4096], which 128 being the sample pairs and 4096 being the activation vector size\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "qsjw8ueUF684"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_np = np.random.rand(100,4096)\n",
        "data_tensor = torch.tensor(data_np)\n",
        "print(data_tensor)\n",
        "print(data_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9WJy6wSIyUw",
        "outputId": "fa611d7d-74c5-42b3-a977-61d700eede66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1991, 0.0471, 0.0378,  ..., 0.4061, 0.0889, 0.4647],\n",
            "        [0.9467, 0.5530, 0.7832,  ..., 0.0520, 0.8006, 0.4639],\n",
            "        [0.9299, 0.2906, 0.7704,  ..., 0.4612, 0.8418, 0.2608],\n",
            "        ...,\n",
            "        [0.7174, 0.5835, 0.8745,  ..., 0.6223, 0.5199, 0.2843],\n",
            "        [0.7495, 0.5361, 0.0674,  ..., 0.2944, 0.7182, 0.3075],\n",
            "        [0.9583, 0.3821, 0.1215,  ..., 0.2201, 0.0928, 0.9772]],\n",
            "       dtype=torch.float64)\n",
            "torch.Size([100, 4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "mean = torch.mean(data_tensor)\n",
        "std = torch.std(data_tensor)\n",
        "data_normalized = (data_tensor-mean)/std"
      ],
      "metadata": {
        "id": "VSc8EX-ldYPr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensor = data_tensor - data_tensor.mean() # center the data\n",
        "cov_matrix = torch.mm(data_tensor.t(), data_tensor) / data_tensor[0]-1 # 100-1"
      ],
      "metadata": {
        "id": "ole00vk0SnUo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues, eigenvectors = np.linalg.eig(np.array(cov_matrix))"
      ],
      "metadata": {
        "id": "xvP2akvaS_Oz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(eigenvalues[0])\n",
        "print(np.max(eigenvalues))\n",
        "# print(eigenvectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noP9-_Q1Z7EJ",
        "outputId": "ad256a18-8f6a-4bb2-9ea7-22f4e22745fd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56142.04512951622+0j)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zipped = zip(eigenvalues, eigenvectors)\n",
        "# lst_zipped = list(zipped)"
      ],
      "metadata": {
        "id": "eI_lPApyYwnA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = sorted(zipped, reverse=True)"
      ],
      "metadata": {
        "id": "IO8ZsYGfZeIp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues, eigenvectors = zip(*res)"
      ],
      "metadata": {
        "id": "umdflcU6ZgCx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eigenvalues[0])\n",
        "print(eigenvectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgaKvkI9ZF-B",
        "outputId": "1b0a7851-50c5-48d9-ea99-444ea640be28"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56142.04512951622+0j)\n",
            "[-0.0056678 +0.j  0.00587951+0.j -0.00903555+0.j ... -0.01162932+0.j\n",
            " -0.01172248+0.j -0.02868854+0.j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pca = torch.pca_lowrank(data_normalized, center=True) # no need to center because its normalized\n",
        "print(len(data_pca))\n",
        "print(data_pca[0].shape) # U\n",
        "print(data_pca[1].shape) # S\n",
        "# S**2/(samplesize-1) contains eigenvectors of ATA/(samplesize-1) which is the covariance of A when center=True is provided\n",
        "print(data_pca[2].shape) # V columns represent the principal directions\n",
        "\n",
        "first_pca = data_pca[2][:, :1] # gets the first principal component\n",
        "print(first_pca, first_pca.shape)\n",
        "first_pca = first_pca.squeeze()\n",
        "print(first_pca, first_pca.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0zyLUt9J7V_",
        "outputId": "e0209bbd-84a9-44b5-8ef6-1316d54874b4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([100, 6])\n",
            "torch.Size([6])\n",
            "torch.Size([4096, 6])\n",
            "tensor([[ 0.0179],\n",
            "        [ 0.0131],\n",
            "        [-0.0043],\n",
            "        ...,\n",
            "        [ 0.0105],\n",
            "        [-0.0141],\n",
            "        [-0.0155]], dtype=torch.float64) torch.Size([4096, 1])\n",
            "tensor([ 0.0179,  0.0131, -0.0043,  ...,  0.0105, -0.0141, -0.0155],\n",
            "       dtype=torch.float64) torch.Size([4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then you apply the first PCA on the same stimuli set S to obtain scores because\n",
        "# \"in practice, the 'reading vector' v is also multiplied by a 'sign' component\"\n",
        "scores = torch.tensor(np.dot(np.array(data_normalized), np.array(first_pca))) # [100,4096] T [4096]\n",
        "# each score should be one-dimensional, so dot product btwn normalized and first pca is needed\n",
        "big_dim_scores = data_normalized*first_pca\n",
        "print(scores.shape)\n",
        "print(big_dim_scores)\n",
        "print()\n",
        "# each stimulus has one score, which is why the shape of scores is torch.Size([100])\n",
        "updated_vectors = first_pca*scores[0] # one stimulus (in the loop, change the index based on the iteration you are on)\n",
        "print(updated_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD5I_YDYMgvF",
        "outputId": "74c01498-46a2-4221-ecb7-9ac556b2dbfe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100])\n",
            "tensor([[-0.0186, -0.0205,  0.0068,  ..., -0.0034,  0.0200,  0.0018],\n",
            "        [ 0.0278,  0.0024, -0.0042,  ..., -0.0162, -0.0147,  0.0019],\n",
            "        [ 0.0267, -0.0094, -0.0040,  ..., -0.0014, -0.0167,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0135,  0.0038, -0.0055,  ...,  0.0045, -0.0010,  0.0115],\n",
            "        [ 0.0155,  0.0017,  0.0064,  ..., -0.0074, -0.0107,  0.0103],\n",
            "        [ 0.0285, -0.0053,  0.0056,  ..., -0.0101,  0.0198, -0.0257]],\n",
            "       dtype=torch.float64)\n",
            "\n",
            "torch.Size([4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_reading_vectors = scores.detach().clone()\n",
        "\n",
        "for i in range(len(scores)):\n",
        "    updated_reading_vectors[i] *= scores[i]"
      ],
      "metadata": {
        "id": "NulDA-T2I2l3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "zlMKC0hqOeC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the hidden states at the token position [-2]\n",
        "# these are normalized uding the parameters derived using the construction of the PCA model in the training phase (mean and std variables from before)\n",
        "# calculate the dot product between the normalized hidden states and out reading vector, which yields a set of scores\n",
        "\n",
        "data_inference = np.random.rand(10,4096)\n",
        "data_inference_tensor = torch.tensor(data_np)\n",
        "data_inference_normalized = (data_inference_tensor-mean)/std\n",
        "data_inference_pca = torch.pca_lowrank(data_inference_normalized) # no need to center because its normalized\n",
        "\n",
        "# first_pca_inference = data_inference_pca[2][:, :1] # gets the first principal component\n",
        "# first_pca_inference = first_pca_inference.squeeze()\n",
        "# print(first_pca_inference, first_pca_inference.shape)\n",
        "\n",
        "scores = data_inference_normalized*first_pca\n",
        "print(scores, scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzDOt0umOdO-",
        "outputId": "c984e818-3190-4575-bd8d-63d6ef803730"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0106,  0.0051, -0.0340,  ...,  0.0030,  0.0175,  0.0054],\n",
            "        [ 0.0158, -0.0006,  0.0209,  ...,  0.0146, -0.0128,  0.0055],\n",
            "        [ 0.0152,  0.0024,  0.0200,  ...,  0.0012, -0.0146,  0.0372],\n",
            "        ...,\n",
            "        [ 0.0077, -0.0010,  0.0277,  ..., -0.0040, -0.0009,  0.0335],\n",
            "        [ 0.0088, -0.0004, -0.0318,  ...,  0.0067, -0.0093,  0.0299],\n",
            "        [ 0.0162,  0.0013, -0.0278,  ...,  0.0091,  0.0173, -0.0747]],\n",
            "       dtype=torch.float64) torch.Size([100, 4096])\n"
          ]
        }
      ]
    }
  ]
}